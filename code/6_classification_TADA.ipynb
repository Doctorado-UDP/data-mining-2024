{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb933f26-1763-4f04-9d2c-6d031b0a1c94",
   "metadata": {},
   "source": [
    "# Modelos de clasificación para texto\n",
    "Bastián González-Bustamante \\\n",
    "Universidad Diego Portales \\\n",
    "Noviembre 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa518525-00ef-42b3-b2d2-42896b413f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56dc4841-25ab-40d0-b6e8-607b89194c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ac8841-904f-416d-8af8-58e3a3c1a2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_obs</th>\n",
       "      <th>coder_1</th>\n",
       "      <th>coder_2</th>\n",
       "      <th>consensus</th>\n",
       "      <th>sec_create_1</th>\n",
       "      <th>sec_create_2</th>\n",
       "      <th>sec_review_1</th>\n",
       "      <th>sec_review_2</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "      <th>...</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>date</th>\n",
       "      <th>tox_60</th>\n",
       "      <th>tox_70</th>\n",
       "      <th>tox_80</th>\n",
       "      <th>tox_90</th>\n",
       "      <th>insult_60</th>\n",
       "      <th>insult_70</th>\n",
       "      <th>insult_80</th>\n",
       "      <th>insult_90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_obs  coder_1  coder_2  consensus  sec_create_1  sec_create_2  \\\n",
       "0  101238        0        0        1.0            46            28   \n",
       "1  119343        0        0        1.0             8             6   \n",
       "2  122343        0        0        1.0             8             6   \n",
       "3  131878        0        0        1.0             4            52   \n",
       "4  132171        0        0        1.0             6            15   \n",
       "\n",
       "   sec_review_1  sec_review_2  possibly_sensitive lang  ...  THREAT  \\\n",
       "0            17             8               False   es  ...     NaN   \n",
       "1             0             2               False   es  ...     NaN   \n",
       "2             1             0               False   es  ...     NaN   \n",
       "3             0             1               False   es  ...     NaN   \n",
       "4             0             1               False   es  ...     NaN   \n",
       "\n",
       "         date tox_60  tox_70  tox_80  tox_90  insult_60  insult_70  insult_80  \\\n",
       "0  2020-08-17      0       0       0       0          0          0          0   \n",
       "1  2020-08-17      0       0       0       0          0          0          0   \n",
       "2  2020-08-17      0       0       0       0          0          0          0   \n",
       "3  2020-08-17      0       0       0       0          0          0          0   \n",
       "4  2020-08-17      0       0       0       0          0          0          0   \n",
       "\n",
       "   insult_90  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load dataset from GitHub URL\n",
    "url = \"https://raw.githubusercontent.com/training-datalab/gold-standard-toxicity/refs/heads/main/data/tidy/goldstd_protests.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "694b62f4-b913-4fc7-bca2-2dcfc2c90b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    ## Lowercase\n",
    "    text = text.lower()\n",
    "    ## Remove punctuation and non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    ## Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca78056-58cf-496e-a547-3070e334ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply preprocessing to the text data\n",
    "df['text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb878241-8776-4bb2-a065-8eaead10908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['coder_1'], test_size=0.2, random_state=86)\n",
    "\n",
    "## Vectorize text data\n",
    "## vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "## Vectorize text data in Spanish\n",
    "spanish_stop_words = stopwords.words('spanish')\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words=spanish_stop_words, ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eafdc3eb-1bb2-4bbf-bdef-2c1adba93871",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define function to train model and evaluate metrics\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822ed737-93e8-473e-94c8-5bfb34ae0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NB\n",
    "nb_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c7c175-af3e-4654-9cbe-db3b4722b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Metrics - Accuracy: 0.7300, Precision: 0.7083, Recall: 0.8947, F1 Score: 0.7907\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Naive Bayes\n",
    "nb_metrics = evaluate_model(nb_model, X_train_vec, y_train, X_test_vec, y_test)\n",
    "print(\"Naive Bayes Metrics - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\".format(*nb_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7f51f51-92e6-4fba-8017-257d35a01092",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter tuning\n",
    "nb_model_ft = MultinomialNB(alpha=0.5)\n",
    "## For Naive Bayes, MultinomialNB has limited tunable parameters, but adjusting the smoothing parameter (alpha) can sometimes improve performance:\n",
    "## alpha: Additive smoothing parameter. A value closer to 0 assumes word frequency distributions are more reliable, but alpha=1.0 is generally a good default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94581f89-8816-46c7-91ff-391d7981d842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Metrics - Accuracy: 0.7250, Precision: 0.7092, Recall: 0.8772, F1 Score: 0.7843\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Naive Bayes\n",
    "nb_metrics_ft = evaluate_model(nb_model_ft, X_train_vec, y_train, X_test_vec, y_test)\n",
    "print(\"Naive Bayes Metrics - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\".format(*nb_metrics_ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd0acfc5-f852-448e-a6ee-729c30267016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm_model = SVC(kernel='linear', random_state=86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fe95d9d-fbb1-41f2-9418-09ae7ca6f9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics - Accuracy: 0.7450, Precision: 0.7890, Recall: 0.7544, F1 Score: 0.7713\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SVM\n",
    "svm_metrics = evaluate_model(svm_model, X_train_vec, y_train, X_test_vec, y_test)\n",
    "print(\"SVM Metrics - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\".format(*svm_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f86423c-e825-4b7e-82e8-61b94113ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter tuning\n",
    "svm_model_ft = SVC(kernel='linear', C=1.0, random_state=86)\n",
    "## For text data, linear kernels often perform well, but you might want to adjust C to control regularization.\n",
    "## C: Regularization parameter. A smaller C increases regularization strength, which can help avoid overfitting but might reduce accuracy.\n",
    "## kernel: The kernel type (linear is generally suitable for text data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5868dc47-199f-485e-8266-8876df12e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics - Accuracy: 0.7450, Precision: 0.7890, Recall: 0.7544, F1 Score: 0.7713\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SVM\n",
    "svm_metrics_ft = evaluate_model(svm_model_ft, X_train_vec, y_train, X_test_vec, y_test)\n",
    "print(\"SVM Metrics - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\".format(*svm_metrics_ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "164f8b8b-a732-4271-9f9a-e2bb92e97efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eea9d08-f1b0-4dce-b50c-a5027d13d8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics - Accuracy: 0.7500, Precision: 0.8636, Recall: 0.6667, F1 Score: 0.7525\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random Forest\n",
    "rf_metrics = evaluate_model(rf_model, X_train_vec, y_train, X_test_vec, y_test)\n",
    "print(\"Random Forest Metrics - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\".format(*rf_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e45e8d47-b48e-488f-aa5e-c49bd91f8082",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter tuning\n",
    "rf_model_ft = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=86)\n",
    "## For Random Forest, you can tune the number of trees, maximum depth, and minimum samples per leaf to optimize its performance:\n",
    "## n_estimators: Number of trees in the forest. More trees can improve accuracy but increase computation time (e.g., 100, 200).\n",
    "## max_depth: Maximum depth of each tree. Limiting depth can prevent overfitting (e.g., max_depth=10).\n",
    "## min_samples_split: Minimum samples required to split an internal node. A higher value can reduce overfitting.\n",
    "## min_samples_leaf: Minimum samples required at a leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1e08e13-3885-408f-b0eb-299974275ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics - Accuracy: 0.6850, Precision: 0.6889, Recall: 0.8158, F1 Score: 0.7470\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random Forest\n",
    "rf_metrics_ft = evaluate_model(rf_model_ft, X_train_vec, y_train, X_test_vec, y_test)\n",
    "print(\"Random Forest Metrics - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\".format(*rf_metrics_ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11fb599d-7b38-4498-9cc4-6ef15081c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost\n",
    "xgb_model = XGBClassifier(eval_metric='logloss', random_state=86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98c56377-215f-4d98-b57b-1f8c8676a9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Metrics - Accuracy: 0.7200, Precision: 0.8152, Recall: 0.6579, F1 Score: 0.7282\n"
     ]
    }
   ],
   "source": [
    "# Evaluate XGBoost\n",
    "xgb_metrics = evaluate_model(xgb_model, X_train_vec, y_train, X_test_vec, y_test)\n",
    "print(\"XGBoost Metrics - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\".format(*xgb_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9aa6ba9e-392d-4975-9a04-3001e936ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter tuning\n",
    "xgb_model_ft = XGBClassifier(eval_metric='logloss', learning_rate=0.1, n_estimators=500, max_depth=6, subsample=0.8, colsample_bytree=0.8, random_state=86)\n",
    "## XGBoost has several parameters that can greatly influence its performance. The learning_rate and n_estimators are especially important.\n",
    "## learning_rate: Controls the step size of each update. Lower values improve generalization (e.g., 0.1, 0.01).\n",
    "## n_estimators: Number of boosting rounds. More rounds usually improve performance but increase training time.\n",
    "## max_depth: Maximum depth of each tree, controlling complexity.\n",
    "## subsample: Fraction of samples used for each tree. Reducing this can help prevent overfitting.\n",
    "## colsample_bytree: Fraction of features used for each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "886fafc6-3ae0-4193-bd24-8f5485d015bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Metrics - Accuracy: 0.7200, Precision: 0.8021, Recall: 0.6754, F1 Score: 0.7333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate XGBoost\n",
    "xgb_metrics_ft = evaluate_model(xgb_model_ft, X_train_vec, y_train, X_test_vec, y_test)\n",
    "print(\"XGBoost Metrics - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\".format(*xgb_metrics_ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b64e46-46d4-45bf-9a43-401902f8c943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
