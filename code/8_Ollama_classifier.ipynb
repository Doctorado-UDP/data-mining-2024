{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f9bffc3-ad16-488d-91e7-8e46c746acce",
   "metadata": {},
   "source": [
    "# LLMs desplegados localemente\n",
    "## Data Mining - Doctorado UDP 2024\n",
    "**Bastián González-Bustamante** \\\n",
    "Noviembre 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a53cf9-7eb9-475c-92b0-7986e19bf11d",
   "metadata": {},
   "source": [
    "## Pandas, Polars and FireDucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b04b4a-1bb8-45e8-8f54-1c9ae0137b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_obs</th>\n",
       "      <th>coder_1</th>\n",
       "      <th>coder_2</th>\n",
       "      <th>consensus</th>\n",
       "      <th>sec_create_1</th>\n",
       "      <th>sec_create_2</th>\n",
       "      <th>sec_review_1</th>\n",
       "      <th>sec_review_2</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "      <th>...</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>date</th>\n",
       "      <th>tox_60</th>\n",
       "      <th>tox_70</th>\n",
       "      <th>tox_80</th>\n",
       "      <th>tox_90</th>\n",
       "      <th>insult_60</th>\n",
       "      <th>insult_70</th>\n",
       "      <th>insult_80</th>\n",
       "      <th>insult_90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_obs  coder_1  coder_2  consensus  sec_create_1  sec_create_2  \\\n",
       "0  101238        0        0        1.0            46            28   \n",
       "1  119343        0        0        1.0             8             6   \n",
       "2  122343        0        0        1.0             8             6   \n",
       "3  131878        0        0        1.0             4            52   \n",
       "4  132171        0        0        1.0             6            15   \n",
       "\n",
       "   sec_review_1  sec_review_2  possibly_sensitive lang  ...  THREAT  \\\n",
       "0            17             8               False   es  ...     NaN   \n",
       "1             0             2               False   es  ...     NaN   \n",
       "2             1             0               False   es  ...     NaN   \n",
       "3             0             1               False   es  ...     NaN   \n",
       "4             0             1               False   es  ...     NaN   \n",
       "\n",
       "         date tox_60  tox_70  tox_80  tox_90  insult_60  insult_70  insult_80  \\\n",
       "0  2020-08-17      0       0       0       0          0          0          0   \n",
       "1  2020-08-17      0       0       0       0          0          0          0   \n",
       "2  2020-08-17      0       0       0       0          0          0          0   \n",
       "3  2020-08-17      0       0       0       0          0          0          0   \n",
       "4  2020-08-17      0       0       0       0          0          0          0   \n",
       "\n",
       "   insult_90  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas: Small to medium-sized datasets\n",
    "import pandas as pd\n",
    "\n",
    "## Load CSV\n",
    "df = pd.read_csv(\"hf://datasets/bgonzalezbustamante/toxicity-protests-ES/goldstd_protests.csv\")\n",
    "\n",
    "## Recoding\n",
    "## df = df[['coder_1','text']]\n",
    "## df['coder_1'] = df['coder_1'].map({0: 'NONTOXIC', 1: 'TOXIC'})\n",
    "\n",
    "## Check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa355427-e9d1-42fb-9f79-94152579e175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 39)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id_obs</th><th>coder_1</th><th>coder_2</th><th>consensus</th><th>sec_create_1</th><th>sec_create_2</th><th>sec_review_1</th><th>sec_review_2</th><th>possibly_sensitive</th><th>lang</th><th>conversation_id</th><th>type</th><th>text</th><th>author_id</th><th>retweet_count</th><th>reply_count</th><th>like_count</th><th>quote_count</th><th>impression_count</th><th>id</th><th>created_at</th><th>in_reply_to_user_id</th><th>error</th><th>TOXICITY</th><th>SEVERE_TOXICITY</th><th>INSULT_EXPERIMENTAL</th><th>THREAT_EXPERIMENTAL</th><th>country</th><th>INSULT</th><th>THREAT</th><th>date</th><th>tox_60</th><th>tox_70</th><th>tox_80</th><th>tox_90</th><th>insult_60</th><th>insult_70</th><th>insult_80</th><th>insult_90</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>bool</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>101238</td><td>0</td><td>0</td><td>1</td><td>46</td><td>28</td><td>17</td><td>8</td><td>false</td><td>&quot;es&quot;</td><td>1.2954e18</td><td>&quot;retweeted&quot;</td><td>&quot;#17AJuntosContraLaImpunidad bu…</td><td>1244484859726376960</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1.2954e18</td><td>&quot;2020-08-17T18:08:58.000Z&quot;</td><td>null</td><td>&quot;No Error&quot;</td><td>0.012378</td><td>0.000744</td><td>0.010059</td><td>0.00611</td><td>&quot;Argentina&quot;</td><td>null</td><td>null</td><td>&quot;2020-08-17&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>119343</td><td>0</td><td>0</td><td>1</td><td>8</td><td>6</td><td>0</td><td>2</td><td>false</td><td>&quot;es&quot;</td><td>1.2954e18</td><td>&quot;quoted&quot;</td><td>&quot;Libres, responsables y republi…</td><td>23677018</td><td>952</td><td>62</td><td>3123</td><td>20</td><td>0</td><td>1.2954e18</td><td>&quot;2020-08-17T19:25:52.000Z&quot;</td><td>null</td><td>&quot;No Error&quot;</td><td>0.015268</td><td>0.000644</td><td>0.012681</td><td>0.00578</td><td>&quot;Argentina&quot;</td><td>null</td><td>null</td><td>&quot;2020-08-17&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>122343</td><td>0</td><td>0</td><td>1</td><td>8</td><td>6</td><td>1</td><td>0</td><td>false</td><td>&quot;es&quot;</td><td>1.2953e18</td><td>&quot;retweeted&quot;</td><td>&quot;@eugeconi @ulises2876 TODOS PO…</td><td>139521663</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1.2954e18</td><td>&quot;2020-08-17T19:31:21.000Z&quot;</td><td>6.15119246e8</td><td>&quot;No Error&quot;</td><td>0.01043</td><td>0.00062</td><td>0.008558</td><td>0.006266</td><td>&quot;Argentina&quot;</td><td>null</td><td>null</td><td>&quot;2020-08-17&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>131878</td><td>0</td><td>0</td><td>1</td><td>4</td><td>52</td><td>0</td><td>1</td><td>false</td><td>&quot;es&quot;</td><td>1.2954e18</td><td>&quot;retweeted&quot;</td><td>&quot;#17AJuntosContraLaImpunidad&nbsp;&nbsp;L…</td><td>1191874719357833216</td><td>1</td><td>0</td><td>2</td><td>0</td><td>0</td><td>1.2954e18</td><td>&quot;2020-08-17T19:48:54.000Z&quot;</td><td>null</td><td>&quot;No Error&quot;</td><td>0.03192</td><td>0.000982</td><td>0.023995</td><td>0.005858</td><td>&quot;Argentina&quot;</td><td>null</td><td>null</td><td>&quot;2020-08-17&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>132171</td><td>0</td><td>0</td><td>1</td><td>6</td><td>15</td><td>0</td><td>1</td><td>false</td><td>&quot;es&quot;</td><td>1.2954e18</td><td>&quot;retweeted&quot;</td><td>&quot;Que nos vea el mundo entero. S…</td><td>979750171348291584</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1.2954e18</td><td>&quot;2020-08-17T19:48:23.000Z&quot;</td><td>null</td><td>&quot;No Error&quot;</td><td>0.012378</td><td>0.000982</td><td>0.009128</td><td>0.006123</td><td>&quot;Argentina&quot;</td><td>null</td><td>null</td><td>&quot;2020-08-17&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 39)\n",
       "┌────────┬─────────┬─────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ id_obs ┆ coder_1 ┆ coder_2 ┆ consensus ┆ … ┆ insult_60 ┆ insult_70 ┆ insult_80 ┆ insult_90 │\n",
       "│ ---    ┆ ---     ┆ ---     ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ i64    ┆ i64     ┆ i64     ┆ i64       ┆   ┆ i64       ┆ i64       ┆ i64       ┆ i64       │\n",
       "╞════════╪═════════╪═════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 101238 ┆ 0       ┆ 0       ┆ 1         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
       "│ 119343 ┆ 0       ┆ 0       ┆ 1         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
       "│ 122343 ┆ 0       ┆ 0       ┆ 1         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
       "│ 131878 ┆ 0       ┆ 0       ┆ 1         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
       "│ 132171 ┆ 0       ┆ 0       ┆ 1         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
       "└────────┴─────────┴─────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Polars: High-performance analytics on data that fit into memory\n",
    "import polars as pl\n",
    "\n",
    "## Load CSV with 'NA' treated as null and pl.Float64 for column that contains large numbers\n",
    "df = pl.read_csv(\"hf://datasets/bgonzalezbustamante/toxicity-protests-ES/goldstd_protests.csv\", null_values=\"NA\",  schema_overrides={\"in_reply_to_user_id\": pl.Float64})\n",
    "\n",
    "## Recoding\n",
    "## df = df.with_columns(\n",
    "    ## pl.when(pl.col(\"coder_1\") == 0)\n",
    "      ## .then(pl.lit(\"NONTOXIC\"))  \n",
    "      ## .when(pl.col(\"coder_1\") == 1\n",
    "      ## .then(pl.lit(\"TOXIC\")) \n",
    "      ## .otherwise(pl.lit(None))  ## Handle unexpected values\n",
    "      ## .alias(\"coder_1\")  \n",
    "## )\n",
    "\n",
    "## Check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dd5bbab-e5d8-4871-a27d-792400deaf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_obs</th>\n",
       "      <th>coder_1</th>\n",
       "      <th>coder_2</th>\n",
       "      <th>consensus</th>\n",
       "      <th>sec_create_1</th>\n",
       "      <th>sec_create_2</th>\n",
       "      <th>sec_review_1</th>\n",
       "      <th>sec_review_2</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "      <th>...</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>date</th>\n",
       "      <th>tox_60</th>\n",
       "      <th>tox_70</th>\n",
       "      <th>tox_80</th>\n",
       "      <th>tox_90</th>\n",
       "      <th>insult_60</th>\n",
       "      <th>insult_70</th>\n",
       "      <th>insult_80</th>\n",
       "      <th>insult_90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_obs  coder_1  coder_2 consensus  sec_create_1  sec_create_2  \\\n",
       "0  101238        0        0         1            46            28   \n",
       "1  119343        0        0         1             8             6   \n",
       "2  122343        0        0         1             8             6   \n",
       "3  131878        0        0         1             4            52   \n",
       "4  132171        0        0         1             6            15   \n",
       "\n",
       "   sec_review_1  sec_review_2  possibly_sensitive lang  ...  THREAT  \\\n",
       "0            17             8               False   es  ...      NA   \n",
       "1             0             2               False   es  ...      NA   \n",
       "2             1             0               False   es  ...      NA   \n",
       "3             0             1               False   es  ...      NA   \n",
       "4             0             1               False   es  ...      NA   \n",
       "\n",
       "        date tox_60  tox_70  tox_80  tox_90  insult_60  insult_70  insult_80  \\\n",
       "0 2020-08-17      0       0       0       0          0          0          0   \n",
       "1 2020-08-17      0       0       0       0          0          0          0   \n",
       "2 2020-08-17      0       0       0       0          0          0          0   \n",
       "3 2020-08-17      0       0       0       0          0          0          0   \n",
       "4 2020-08-17      0       0       0       0          0          0          0   \n",
       "\n",
       "   insult_90  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FireDucks (DuckDB): SQL-like syntax and handling out-of-memory datasets\n",
    "import duckdb \n",
    "\n",
    "## Load CSV into a DuckDB-managed frame\n",
    "con = duckdb.connect()\n",
    "df = con.execute(\"SELECT * FROM read_csv_auto('hf://datasets/bgonzalezbustamante/toxicity-protests-ES/goldstd_protests.csv')\").fetchdf()\n",
    "\n",
    "## Recoding\n",
    "## df = df[['coder_1','text']]\n",
    "## df['coder_1'] = df['coder_1'].map({0: 'NONTOXIC', 1: 'TOXIC'})\n",
    "\n",
    "## Check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbc3a41-9eb9-4da1-909c-e81375dc18be",
   "metadata": {},
   "source": [
    "## Ollama straightforward classifier\n",
    "### Only for pandas\n",
    "**This approach is straightforward but slightly more prone to index-related errors (depending on the number of cases). It could be improved by iterating directly over rows of data frame**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4e73e3-1a08-44e7-83e8-b81625b15944",
   "metadata": {},
   "source": [
    "### Zero-Shot Classification\n",
    "**Simple yet effective**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce2287ff-ac85-4fd9-b094-76b8bd514f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying comments: 100%|██████████| 1000/1000 [00:57<00:00, 17.48it/s]\n"
     ]
    }
   ],
   "source": [
    "## Dependencies\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "\n",
    "## Model\n",
    "model = \"llama3.2\"\n",
    "\n",
    "## Store classification results\n",
    "df[\"annotation\"] = \"\" \n",
    "\n",
    "## Zero-shot with a progress bar\n",
    "for i in tqdm(range(len(df)), desc=\"Classifying comments\"):\n",
    "    chat_response = ollama.chat(\n",
    "        model=model,\n",
    "        options={\"seed\":86,\"temperature\":0,\"top_p\":0.9,\"repeat_penalty\":1.1,\"top_k\":40,\"min_p\":0,\"num_ctx\":2048},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Classify the category of the comment as either TOXIC or NONTOXIC. TOXIC: Rude, disrespectful, or unreasonable comments that are likely to make someone leave the discussion or stop sharing their perspective. NONTOXIC: Civil or nice comments that are unlikely to discourage conversation.\" \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"text: {df.loc[i, 'text']} \"\n",
    "                    \"\\nRespond with only the category (TOXIC or NONTOXIC). Do not provide any additional analysis or explanation.\"\n",
    "                ),\n",
    "                },\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    ## Store the result in the 'classification' column\n",
    "    df.at[i, \"annotation\"] = chat_response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a8ce3e7-20d9-4ed1-92c6-7b73d2a19c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation\n",
      "TOXIC                                                                                                     742\n",
      "NONTOXIC                                                                                                  257\n",
      "I cannot classify this comment as it contains hate speech. Is there anything else I can help you with?      1\n",
      "Name: count, dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## Summary\n",
    "print(df[\"annotation\"].value_counts())\n",
    "print(df[\"annotation\"].isna().sum())\n",
    "unique_values = df[\"annotation\"].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f34db518-e8f3-4bdc-bd2f-d5f5503a2acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation\n",
      "1    742\n",
      "0    258\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Mapping labels\n",
    "mapping = {unique_values[0]: 1, unique_values[1]: 0, unique_values[2]: 0}\n",
    "df['annotation'] = df['annotation'].map(mapping)\n",
    "print(df[\"annotation\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4432f924-e1e0-443a-a82c-6db814d12030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 Precision: 0.6711590296495957 Recall 0.9325842696629213 F1-Score 0.780564263322884\n"
     ]
    }
   ],
   "source": [
    "## Performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(df[\"coder_1\"], df[\"annotation\"])\n",
    "precision = precision_score(df[\"coder_1\"], df[\"annotation\"], average=\"binary\")\n",
    "recall = recall_score(df[\"coder_1\"], df[\"annotation\"], average=\"binary\")\n",
    "f1 = f1_score(df[\"coder_1\"], df[\"annotation\"], average=\"binary\")\n",
    "print(\"Accuracy:\", accuracy, \"Precision:\", precision, \"Recall\", recall, \"F1-Score\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f139fe-c4fe-4de0-94b9-b98a13ebd6c8",
   "metadata": {},
   "source": [
    "### Few-Shot Classification\n",
    "**More complex, but requires good examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b6f1876-73b5-4b09-8a45-655e819b0276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying comments: 100%|██████████| 1000/1000 [01:00<00:00, 16.52it/s]\n"
     ]
    }
   ],
   "source": [
    "## Dependencies\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "\n",
    "## Model\n",
    "model = \"llama3.2\"\n",
    "\n",
    "## Few-shot examples\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Classify the category of the comment as either TOXIC or NONTOXIC. TOXIC: Rude, disrespectful, or unreasonable comments that are likely to make someone leave the discussion or stop sharing their perspective. NONTOXIC: Civil or nice comments that are unlikely to discourage conversation.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"text: 'Eres un idiota.'\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"TOXIC\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"text: 'Muchas gracias por tu interesante comentario.'\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"NONTOXIC\"\n",
    "    }\n",
    "]\n",
    "\n",
    "## Store classification results\n",
    "df[\"annotation\"] = \"\"\n",
    "\n",
    "## Few-shot classification with a progress bar\n",
    "for i in tqdm(range(len(df)), desc=\"Classifying comments\"):\n",
    "    chat_response = ollama.chat(\n",
    "        model=model,\n",
    "        options={\"seed\": 86, \"temperature\": 0, \"top_p\": 0.9, \"repeat_penalty\": 1.1, \"top_k\": 40, \"min_p\": 0, \"num_ctx\": 2048},\n",
    "        messages=few_shot_examples + [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"text: {df.loc[i, 'text']} \"\n",
    "                    \"\\nRespond with only the category (TOXIC or NONTOXIC). Do not provide any additional analysis or explanation.\"\n",
    "                )\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    ## Store the result in the 'classification' column\n",
    "    df.at[i, \"annotation\"] = chat_response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa79f66b-cda0-43e9-b1b9-025f599ad92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation\n",
      "TOXIC       880\n",
      "NONTOXIC    120\n",
      "Name: count, dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## Summary\n",
    "print(df[\"annotation\"].value_counts())\n",
    "print(df[\"annotation\"].isna().sum())\n",
    "unique_values = df[\"annotation\"].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "171335a5-25b2-4a4e-9472-69beba192ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation\n",
      "1    880\n",
      "0    120\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Mapping labels\n",
    "mapping = {unique_values[0]: 1, unique_values[1]: 0}\n",
    "df['annotation'] = df['annotation'].map(mapping)\n",
    "print(df[\"annotation\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a9973e6-ab16-434d-b017-cad91de814c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.638 Precision: 0.5977272727272728 Recall 0.9850187265917603 F1-Score 0.743988684582744\n"
     ]
    }
   ],
   "source": [
    "## Performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(df[\"coder_1\"], df[\"annotation\"])\n",
    "precision = precision_score(df[\"coder_1\"], df[\"annotation\"], average=\"binary\")\n",
    "recall = recall_score(df[\"coder_1\"], df[\"annotation\"], average=\"binary\")\n",
    "f1 = f1_score(df[\"coder_1\"], df[\"annotation\"], average=\"binary\")\n",
    "print(\"Accuracy:\", accuracy, \"Precision:\", precision, \"Recall\", recall, \"F1-Score\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881eb3d-5cd3-4e8b-b325-e37e7d795ad5",
   "metadata": {},
   "source": [
    "### Chain-of-Thought Classification\n",
    "**It is time-consuming and does not always offer improvements; it depends significantly on the model (better performance in larger models) and the labelling structure. JSON should give better results** \\\n",
    "**Some models might not strictly adhere to the prompt instructions due to their training process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397800e0-7afa-44c1-9884-70b84ba207a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying comments: 100%|██████████| 1000/1000 [21:21<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "## Dependencies\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "## Model\n",
    "model = \"llama3.2\"\n",
    "\n",
    "## Store classification results\n",
    "df[\"annotation\"] = \"\"\n",
    "df[\"reasoning\"] = \"\"\n",
    "\n",
    "## Chain-of-Thought classification with a progress bar\n",
    "for i in tqdm(range(len(df)), desc=\"Classifying comments\"):\n",
    "    chat_response = ollama.chat(\n",
    "        model=model,\n",
    "        options={\"seed\": 86, \"temperature\": 0, \"top_p\": 0.9, \"repeat_penalty\": 1.1, \"top_k\": 40, \"min_p\": 0, \"num_ctx\": 2048},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"Classify the category of the comment as either TOXIC or NONTOXIC. TOXIC: Rude, disrespectful, or unreasonable comments that are likely to make someone leave the discussion or stop sharing their perspective. NONTOXIC: Civil or nice comments that are unlikely to discourage conversation. \"\n",
    "                     \"First, provide your reasoning step-by-step. On a new line, explicitly state the category in the exact format: 'Label: TOXIC' or 'Label: NONTOXIC'. Do not include any additional text after the label.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"text: {df.loc[i, 'text']} \"\n",
    "                    \"\\nFirst, explain your reasoning step-by-step. Then, conclude with the label on a new line in the exact format: 'Label: TOXIC' or 'Label: NONTOXIC'.\"\n",
    "                )\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    ## Parse the response\n",
    "    response_content = chat_response['message']['content']\n",
    "    label_match = re.search(r\"Label:\\s*(TOXIC|NONTOXIC)\", response_content, re.IGNORECASE)\n",
    "    if label_match:\n",
    "        final_label = label_match.group(1).upper()\n",
    "        reasoning = response_content[:label_match.start()].strip()\n",
    "    else:\n",
    "        final_label = \"INVALID\"\n",
    "        reasoning = response_content.strip()\n",
    "\n",
    "    ## Store the results\n",
    "    df.at[i, \"reasoning\"] = reasoning\n",
    "    df.at[i, \"annotation\"] = final_label if final_label in [\"TOXIC\", \"NONTOXIC\"] else \"INVALID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89880ebc-f7fc-4844-9a8e-eeedec3c143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation\n",
      "TOXIC       754\n",
      "NONTOXIC    201\n",
      "INVALID      45\n",
      "Name: count, dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## Summary\n",
    "print(df[\"annotation\"].value_counts())\n",
    "print(df[\"annotation\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "586392c4-e2a6-47c1-b42f-e3c1a6624d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_annotation\n",
      "TOXIC            764\n",
      "NONTOXIC         220\n",
      "REVIEW_NEEDED     16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Post-process reasoning for reclassification\n",
    "def reclassify_from_reasoning(reasoning):\n",
    "    reasoning_lower = reasoning.lower()\n",
    "    if 'toxic' in reasoning_lower and 'non' not in reasoning_lower:\n",
    "        return 'TOXIC'\n",
    "    elif 'non-toxic' in reasoning_lower or 'not toxic' in reasoning_lower or 'nontoxic' in reasoning_lower:\n",
    "        return 'NONTOXIC'\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "## Create 'final_annotation'\n",
    "df['final_annotation'] = df['annotation']\n",
    "\n",
    "## Identify INVALID rows\n",
    "invalid_mask = df['annotation'] == 'INVALID'\n",
    "\n",
    "## Apply the reclassification function\n",
    "df.loc[invalid_mask, 'final_annotation'] = df.loc[invalid_mask, 'reasoning'].apply(reclassify_from_reasoning)\n",
    "\n",
    "## Labels for manual review\n",
    "unknown_mask = df['final_annotation'] == 'UNKNOWN'\n",
    "df.loc[unknown_mask, 'final_annotation'] = 'REVIEW_NEEDED'\n",
    "\n",
    "## Values for mapping\n",
    "unique_values = df[\"final_annotation\"].value_counts().index.tolist()\n",
    "print(df[\"final_annotation\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ad6ac49-df36-4892-9a47-630a156f30f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_annotation\n",
      "1    764\n",
      "0    236\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Mapping labels\n",
    "mapping = {unique_values[0]: 1, unique_values[1]: 0, unique_values[2]: 0}\n",
    "df['final_annotation'] = df['final_annotation'].map(mapping)\n",
    "print(df[\"final_annotation\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f199ff48-64bd-49a7-9905-4c2e49ec5b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.652 Precision: 0.6217277486910995 Recall 0.8895131086142322 F1-Score 0.7318952234206472\n"
     ]
    }
   ],
   "source": [
    "## Performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(df[\"coder_1\"], df[\"final_annotation\"])\n",
    "precision = precision_score(df[\"coder_1\"], df[\"final_annotation\"], average=\"binary\")\n",
    "recall = recall_score(df[\"coder_1\"], df[\"final_annotation\"], average=\"binary\")\n",
    "f1 = f1_score(df[\"coder_1\"], df[\"final_annotation\"], average=\"binary\")\n",
    "print(\"Accuracy:\", accuracy, \"Precision:\", precision, \"Recall\", recall, \"F1-Score\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb467d42-9336-4ce9-8dd5-77944ce901de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
